{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Telegram_mens 07.09.xlsx', header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,:2]\n",
    "df.columns = ['Mensagem','Classificação']\n",
    "df.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df['Classificação']!=1) & (df['Classificação']!=0)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://bit.ly/3yZpz9A ATENÇÃO: RECADO PARA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Padre Gabriel mostra a verdade sobre maçona...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quando voce se sentir um idiota, veja essa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>_Boa noite meus irmãos do BEM, pacíficos e o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>...A fraudemia é um plano arquitetado pelos ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>4884</td>\n",
       "      <td>Zetinhahttps://youtu.be/vB31fGZ5m6IYouTube#07/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>4885</td>\n",
       "      <td>Zetinhahttps://youtu.be/Yhy5KEmOFjEYouTubeVeja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>4886</td>\n",
       "      <td>Zetinhahttps://youtu.be/znQIxxKQ_R4YouTubeOLHA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>4887</td>\n",
       "      <td>zeyton santiz tudo se transforma em magia .......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>4888</td>\n",
       "      <td>Zoe Martinez é uma verdadeira representante da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                           Mensagem Classificação\n",
       "0         0     https://bit.ly/3yZpz9A ATENÇÃO: RECADO PARA...             1\n",
       "1         1     Padre Gabriel mostra a verdade sobre maçona...             0\n",
       "2         2     Quando voce se sentir um idiota, veja essa ...             1\n",
       "3         3    _Boa noite meus irmãos do BEM, pacíficos e o...             1\n",
       "4         4    ...A fraudemia é um plano arquitetado pelos ...             0\n",
       "...     ...                                                ...           ...\n",
       "3972   4884  Zetinhahttps://youtu.be/vB31fGZ5m6IYouTube#07/...             0\n",
       "3973   4885  Zetinhahttps://youtu.be/Yhy5KEmOFjEYouTubeVeja...             1\n",
       "3974   4886  Zetinhahttps://youtu.be/znQIxxKQ_R4YouTubeOLHA...             1\n",
       "3975   4887  zeyton santiz tudo se transforma em magia .......             0\n",
       "3976   4888  Zoe Martinez é uma verdadeira representante da...             0\n",
       "\n",
       "[3977 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.Mensagem.to_list()\n",
    "labels = df.Classificação.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 3500\n",
    "\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "\n",
    "training_labels = labels [0:training_size]\n",
    "testing_labels = labels [training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "max_length = 400\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# creating training sequences and padding them\n",
    "traning_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(traning_sequences, maxlen = max_length,\n",
    "                                padding = padding_type,\n",
    "                                truncating=trunc_type,\n",
    "                                )\n",
    "\n",
    "# creating  testing sequences and padding them using same tokenizer\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen = max_length,\n",
    "                                padding = padding_type,\n",
    "                                truncating=trunc_type,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "model  = tf.keras.Sequential([\n",
    "                # addinging an Embedding layer for Neural Network to learn the vectors\n",
    "                tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(),\n",
    "                tf.keras.layers.Dense(24, activation = 'relu'),\n",
    "                tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.3130 - accuracy: 0.8671 - val_loss: 0.6270 - val_accuracy: 0.7128\n",
      "Epoch 2/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.3012 - accuracy: 0.8749 - val_loss: 0.6058 - val_accuracy: 0.7526\n",
      "Epoch 3/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.2887 - accuracy: 0.8837 - val_loss: 0.6133 - val_accuracy: 0.7484\n",
      "Epoch 4/15\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.2787 - accuracy: 0.8911 - val_loss: 0.6187 - val_accuracy: 0.7463\n",
      "Epoch 5/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.2664 - accuracy: 0.8909 - val_loss: 0.6305 - val_accuracy: 0.7484\n",
      "Epoch 6/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.2584 - accuracy: 0.8951 - val_loss: 0.6370 - val_accuracy: 0.7547\n",
      "Epoch 7/15\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.2441 - accuracy: 0.9037 - val_loss: 0.6631 - val_accuracy: 0.7212\n",
      "Epoch 8/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.2369 - accuracy: 0.9060 - val_loss: 0.6541 - val_accuracy: 0.7547\n",
      "Epoch 9/15\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.2341 - accuracy: 0.9071 - val_loss: 0.6652 - val_accuracy: 0.7526\n",
      "Epoch 10/15\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.2245 - accuracy: 0.9129 - val_loss: 0.7043 - val_accuracy: 0.7065\n",
      "Epoch 11/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.2148 - accuracy: 0.9209 - val_loss: 0.7044 - val_accuracy: 0.7212\n",
      "Epoch 12/15\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.2069 - accuracy: 0.9234 - val_loss: 0.7246 - val_accuracy: 0.7233\n",
      "Epoch 13/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.2014 - accuracy: 0.9209 - val_loss: 0.7095 - val_accuracy: 0.7463\n",
      "Epoch 14/15\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1937 - accuracy: 0.9306 - val_loss: 0.7216 - val_accuracy: 0.7400\n",
      "Epoch 15/15\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1854 - accuracy: 0.9311 - val_loss: 0.7304 - val_accuracy: 0.7442\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_padded,training_labels, epochs = 15,\n",
    "                    validation_data = (testing_padded,testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24040264]\n",
      " [0.76771903]]\n"
     ]
    }
   ],
   "source": [
    "# sentence 1 is bit sarcastic, whereas sentence two is a general statment.\n",
    "new_sentence = [\n",
    "                \"Eu odeio bolsonaro, aquele filha da puta\",\n",
    "                \"Eu apoio todo o brasil\"\n",
    "                ]\n",
    "\n",
    "# Converting the sentences to sequences using tokenizer\n",
    "new_sequences = tokenizer.texts_to_sequences(new_sentence)\n",
    "new_padded = pad_sequences(new_sequences, maxlen = max_length,\n",
    "                           padding = padding_type,\n",
    "                           truncating = trunc_type)\n",
    "\n",
    "new_padded = np.array(new_padded )\n",
    "\n",
    "print(model.predict(new_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[83, 1, 21, 1588, 987, 9, 3820], [83, 241, 122, 3, 13]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "model.save('Model_NLP.h5')\n",
    "print('Model Saved!')\n",
    "model.save_weights('Weights_NLP.h5')\n",
    "print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp: \n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = {'Tokenizer':tokenizer, 'vocab_size':5000, 'max_length': 400, 'trunc_type':'post', 'padding_type':'post','oov_tok': \"<OOV>\"}\n",
    "\n",
    "save_object(objs, 'Functions_to_nlp.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Functions_to_nlp.obj', 'rb') as inp:\n",
    "    tech_companies = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tokenizer': <keras_preprocessing.text.Tokenizer at 0x1acae7004f0>,\n",
       " 'vocab_size': 5000,\n",
       " 'max_length': 400,\n",
       " 'trunc_type': 'post',\n",
       " 'padding_type': 'post',\n",
       " 'oov_tok': '<OOV>'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_companies"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "156095e88c4122aa910a4b0fbc57328cd046ae399e7b0a439b87a86bea47efda"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
